import torch
import torch.nn as nn
from torchvision import models
import os

# ==========================================================
# 1. æ¨¡å‹å®šä¹‰ (å¿…é¡»ä¸è®­ç»ƒæ—¶çš„å®šä¹‰å®Œå…¨ä¸€è‡´)
# ==========================================================
class RegressionResNet50(nn.Module):
    def __init__(self, pretrained=False): # è½¬æ¢æ—¶ä¸éœ€è¦é¢„è®­ç»ƒæƒé‡ï¼Œåªéœ€è¦ç»“æ„
        super().__init__()
        # æ³¨æ„ï¼šè¿™é‡Œ weights è®¾ç½®ä¸º Noneï¼Œå› ä¸ºæˆ‘ä»¬ä¼šåŠ è½½ä½ è®­ç»ƒå¥½çš„ .pth æƒé‡
        self.backbone = models.resnet50(weights=None)
        in_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Linear(in_features, 1)

    def forward(self, x):
        return self.backbone(x)

def convert_to_onnx():
    # ==========================================================
    # 2. é…ç½®è·¯å¾„å’Œå‚æ•°
    # ==========================================================
    model_path = "best_resnet50_regression.pth"
    onnx_path = "best_resnet50_regression.onnx"
    
    # è¾“å…¥å°ºå¯¸: (Batch_Size, Channels, Height, Width)
    # ä½ çš„è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨çš„æ˜¯ 224x224
    input_shape = (1, 3, 224, 224) 
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    #Check file exists
    if not os.path.exists(model_path):
        print(f"Error: Model file '{model_path}' not found.")
        return

    # ==========================================================
    # 3. åŠ è½½æ¨¡å‹
    # ==========================================================
    print("Loading model structure...")
    model = RegressionResNet50(pretrained=False)
    
    print(f"Loading weights from {model_path}...")
    try:
        state_dict = torch.load(model_path, map_location=device)
        model.load_state_dict(state_dict)
    except Exception as e:
        print(f"Error loading weights: {e}")
        return

    model.to(device)
    model.eval() # å¿…é¡»è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œå¦åˆ™ BatchNormalization ç­‰å±‚è¡Œä¸ºä¸æ­£ç¡®

    # ==========================================================
    # 4. å¯¼å‡º ONNX
    # ==========================================================
    print("Creating dummy input...")
    dummy_input = torch.randn(input_shape).to(device)

    print(f"Exporting to {onnx_path}...")
    try:
        # 1. å…ˆå¯¼å‡ºæ¨¡å‹
        torch.onnx.export(
            model,                      # æ¨¡å‹å®ä¾‹
            dummy_input,                # è™šæ‹Ÿè¾“å…¥
            onnx_path,                  # è¾“å‡ºæ–‡ä»¶è·¯å¾„
            verbose=False,              # æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            input_names=['input'],      # è¾“å…¥èŠ‚ç‚¹åç§°
            output_names=['output'],    # è¾“å‡ºèŠ‚ç‚¹åç§°
            opset_version=11,           # ONNX opset ç‰ˆæœ¬
            dynamic_axes={              # åŠ¨æ€è½´
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        print(f"âœ… Initial export successful to: {onnx_path}")

        # 2. å°è¯•åˆå¹¶ .data æ–‡ä»¶ (å¦‚æœæœ‰ç”Ÿæˆ)
        # æŸäº› PyTorch ç‰ˆæœ¬æˆ–é…ç½®ä¼šç”Ÿæˆ .onnx å’Œ .onnx.data ä¸¤ä¸ªæ–‡ä»¶
        # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ onnx åº“é‡æ–°ä¿å­˜ä¸€æ¬¡ï¼Œå°†å…¶åˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶
        try:
            import onnx
            print("ğŸ”„ Checking for split files and merging if necessary...")
            
            # åŠ è½½å¯¼å‡ºçš„æ¨¡å‹ï¼ˆä¼šè‡ªåŠ¨åŠ è½½å…³è”çš„ .data æ–‡ä»¶ï¼‰
            onnx_model = onnx.load(onnx_path)
            
            # é‡æ–°ä¿å­˜ï¼ˆonnx.save é»˜è®¤ä¼šå°†æƒé‡åµŒå…¥åˆ°æ¨¡å‹æ–‡ä»¶ä¸­ï¼Œé™¤éæ¨¡å‹ > 2GBï¼‰
            onnx.save(onnx_model, onnx_path)
            
            # æ£€æŸ¥å¹¶åˆ é™¤å¯èƒ½å­˜åœ¨çš„ .data æ–‡ä»¶
            data_file = onnx_path + ".data"
            if os.path.exists(data_file):
                os.remove(data_file)
                print(f"ğŸ—‘ï¸ Removed external data file: {data_file}")
            
            print(f"âœ… Merged into single file: {onnx_path}")
            
            # éªŒè¯æ¨¡å‹
            onnx.checker.check_model(onnx_model)
            print("âœ… ONNX model check passed.")
            
        except ImportError:
            print("âš ï¸ 'onnx' library not found. If you see a .data file, install 'onnx' (pip install onnx) and run this again to merge them.")
        except Exception as e:
            print(f"âš ï¸ Merge/Check process failed (model is still usable): {e}")

    except Exception as e:
        print(f"âŒ Export failed: {e}")

if __name__ == "__main__":
    convert_to_onnx()